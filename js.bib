@comment{jabref-meta: databaseType:bibtex;}

@article{denard2009london,
  title={The London Charter for the computer-based visualisation of cultural heritage},
  author={Denard, Hugh and others},
  journal={no. February},
  pages={1--13},
  year={2009}
}

@book{gitelman_raw_2013,
	address = {Cambridge, Massachusetts ; London, England},
	title = {Raw {Data} {Is} an {Oxymoron}},
	isbn = {978-0-262-51828-4},
	abstract = {Episodes in the history of data, from early modern math problems to today's inescapable "dataveillance," that demonstrate the dependence of data on culture.We live in the era of Big Data, with storage and transmission capacity measured not just in terabytes but in petabytes (where peta- denotes a quadrillion, or a thousand trillion). Data collection is constant and even insidious, with every click and every "like" stored somewhere for something. This book reminds us that data is anything but "raw," that we shouldn't think of data as a natural resource but as a cultural one that needs to be generated, protected, and interpreted. The book's essays describe eight episodes in the history of data from the predigital to the digital. Together they address such issues as the ways that different kinds of data and different domains of inquiry are mutually defining; how data are variously "cooked" in the processes of their collection and use; and conflicts over what can―or can't―be "reduced" to data. Contributors discuss the intellectual history of data as a concept; describe early financial modeling and some unusual sources for astronomical data; discover the prehistory of the database in newspaper clippings and index cards; and consider contemporary "dataveillance" of our online habits as well as the complexity of scientific data curation. Essay AuthorsGeoffrey C. Bowker, Kevin R. Brine, Ellen Gruber Garvey, Lisa Gitelman, Steven J. Jackson, Virginia Jackson, Markus Krajewski, Mary Poovey, Rita Raley, David Ribes, Daniel Rosenberg, Matthew Stanley, Travis D. Williams},
	language = {English},
	publisher = {The MIT Press},
	editor = {Gitelman, Lisa},
	month = jan,
	year = {2013}
}

@misc{university_of_york_department_of_archaeology_heritage_2017,
	title = {The {Heritage} {Jam}},
	url = {http://www.heritagejam.org/home2/},
	language = {en-GB},
	urldate = {2018-08-15},
	journal = {The Heritage Jam},
	author = {University of York Department of Archaeology},
	year = {2017},
	file = {Snapshot:/home/jolene/Zotero/storage/ZLL69L4B/home2.html:text/html}
}

@article{marwick_computational_2016,
	Author = {Marwick, Ben},
	File = {Snapshot:/Users/shawngraham/Library/Application Support/Zotero/Profiles/rcpe5jts.default/zotero/storage/NCT4Q4ZA/s10816-015-9272-9.html:text/html},
	Journal = {Journal of Archaeological Method and Theory},
	Keywords = {data publication},
	Pages = {1--27},
	Shorttitle = {Computational reproducibility in archaeological research},
	Title = {Computational reproducibility in archaeological research: basic principles and a case study of their implementation},
	Url = {http://link.springer.com/article/10.1007/s10816-015-9272-9},
	Urldate = {2017-02-16},
	Year = {2016},
	Bdsk-Url-1 = {http://link.springer.com/article/10.1007/s10816-015-9272-9}}


  @article{broman_data_2018,
  	title = {Data {Organization} in {Spreadsheets}},
  	volume = {72},
  	issn = {0003-1305},
  	url = {https://doi.org/10.1080/00031305.2017.1375989},
  	doi = {10.1080/00031305.2017.1375989},
  	abstract = {Spreadsheets are widely used software tools for data entry, storage, analysis, and visualization. Focusing on the data entry and storage aspects, this article offers practical recommendations for organizing spreadsheet data to reduce errors and ease later analyses. The basic principles are: be consistent, write dates like YYYY-MM-DD, do not leave any cells empty, put just one thing in a cell, organize the data as a single rectangle (with subjects as rows and variables as columns, and with a single header row), create a data dictionary, do not include calculations in the raw data files, do not use font color or highlighting as data, choose good names for things, make backups, use data validation to avoid data entry errors, and save the data in plain text files.},
  	number = {1},
  	urldate = {2018-08-19},
  	journal = {The American Statistician},
  	author = {Broman, Karl W. and Woo, Kara H.},
  	month = jan,
  	year = {2018},
  	keywords = {Data management, Data organization, Microsoft Excel, Spreadsheets},
  	pages = {2--10},
  	file = {Full Text PDF:/home/jolene/Zotero/storage/L6BGHTHI/Broman and Woo - 2018 - Data Organization in Spreadsheets.pdf:application/pdf;Snapshot:/home/jolene/Zotero/storage/TZHQYSM3/00031305.2017.html:text/html}
  }

  @article{ziemann_gene_2016,
  	title = {Gene name errors are widespread in the scientific literature},
  	volume = {17},
  	issn = {1474-760X},
  	url = {https://doi.org/10.1186/s13059-016-1044-7},
  	doi = {10.1186/s13059-016-1044-7},
  	abstract = {The spreadsheet software Microsoft Excel, when used with default settings, is known to convert gene names to dates and floating-point numbers. A programmatic scan of leading genomics journals reveals that approximately one-fifth of papers with supplementary Excel gene lists contain erroneous gene name conversions.},
  	number = {1},
  	urldate = {2018-09-01},
  	journal = {Genome Biology},
  	author = {Ziemann, Mark and Eren, Yotam and El-Osta, Assam},
  	month = aug,
  	year = {2016},
  	pages = {177},
  	file = {Full Text PDF:/home/jolene/Zotero/storage/NLPNCF4I/Ziemann et al. - 2016 - Gene name errors are widespread in the scientific .pdf:application/pdf;Snapshot:/home/jolene/Zotero/storage/Q6SJITHN/s13059-016-1044-7.html:text/html}
  }

  @article{wilson_good_2017,
	title = {Good enough practices in scientific computing},
	volume = {13},
	issn = {1553-7358},
	url = {http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005510},
	doi = {10.1371/journal.pcbi.1005510},
	abstract = {Author summary Computers are now essential in all branches of science, but most researchers are never taught the equivalent of basic lab skills for research computing. As a result, data can get lost, analyses can take much longer than necessary, and researchers are limited in how effectively they can work with software and data. Computing workflows need to follow the same practices as lab projects and notebooks, with organized data, documented steps, and the project structured for reproducibility, but researchers new to computing often don't know where to start. This paper presents a set of good computing practices that every researcher can adopt, regardless of their current level of computational skill. These practices, which encompass data management, programming, collaborating with colleagues, organizing projects, tracking work, and writing manuscripts, are drawn from a wide variety of published sources from our daily lives and from our work with volunteer organizations that have delivered workshops to over 11,000 people since 2010.},
	language = {en},
	number = {6},
	urldate = {2018-04-09},
	journal = {PLOS Computational Biology},
	author = {Wilson, Greg and Bryan, Jennifer and Cranston, Karen and Kitzes, Justin and Nederbragt, Lex and Teal, Tracy K.},
	month = jun,
	year = {2017},
	keywords = {Data management, Computer software, Control systems, Data processing, Programming languages, Reproducibility, Software tools, Source code},
	pages = {e1005510},
	file = {Full Text PDF:/home/jolene/Zotero/storage/Z6K4Y8BF/Wilson et al. - 2017 - Good enough practices in scientific computing.pdf:application/pdf;Snapshot:/home/jolene/Zotero/storage/88W58PN9/article.html:text/html}
}
