## 3D Photogrammetry & Structure from Motion

In recent years, faster and more powerful computers have made it feasible to do complex 3d model building by extracting points of overlap in multiple photographs, then extrapolating from the camera metadata embedded in those images the distance from the points to the camera's image sensor. This information allows the reconstruction of where those points were _in space_ relative to the camera. Thus astonishingly good 3d models can be created at rather low cost. 

Laser scanning, on the other hand, involves shooting rays of light onto an object (or space) and counting the time it takes for the light to return to the scanner. Laser scanners are able therefore to take detailed micro-millimetre scans of an object's surface and texture. For some archaeological purposes, laser scanning is to be preferred. For other purposes, 3d photogrammetry or 'structure from motion' (sfm) is entirely appropriate, and the level of resolution good enough

In this chapter, we'll cover some of the basic principles of how sfm works while pointing you to more detailed discussions. We also provide links in the 'further readings' to some recent case studies using 3d photogrammetry in novel ways.


Basic principles

- image capture
- image matching
- dense point cloud generation
- secondary product generation
- analysis / presentation

take overlapping images; you want a high degree of overlap

tie points are matched

camera orientations are deduced

dense point cloud generated

chief ray is the line from the object, through the lens, to the image plate

intersection of many of these allows the software to work out the location of the point in space

- knowing the 'interior and exterior' orientation of the camera - its internal arrangements, including lens distortion, focal length and so on from the metadata bundled with the image, allows software to work out the position of the camera viz points of overlap in the images

- the intersection of rays then allows us to work out the location of these points in space

- resulting point cloud has an arbitrary scale and coordinate frame (ways around this)

sfm process
- identifies control points that are visible in multiple images (default in agisoft photoscan is 40 000 _per image_)
- best control points are then matched
- then triangulation (more or less) to work out the relative position & orientation of every image

this is the sparse reconstruction

now dense reconstruction

- repeats the process above but for all possible control points
- a 'triangulated irregular network' TIN is generated, a mesh, onto which textures can be mapped using regular graphics software

then what?

- download to your computer; clean up


### discussion

### exercises

### nuts and bolts
In order to use something like [Regard3d](http://www.regard3d.org/) to build models from _pictures you've taken with your cellphone_, you need to add certain information to

a) the images themselves
b) the database of cameras that Regard3d knows.

**if you've taken pictures with an actual digital camera, chances are that this information is already present and you're good to go** You'll know if you need to add information if you add a picture set to Regard3d and it says 'NA' beside the picture.

#### Adding metadata to images
1. Go to [https://www.sno.phy.queensu.ca/~phil/exiftool/index.html](https://www.sno.phy.queensu.ca/~phil/exiftool/index.html) and download the version of the Exiftool appropriate to your computer. 
 - **Windows users** you need to fully extract the tool from the zipped download. **THEN** you need to rename the file to just `exiftool.exe`. When you extract it, the tool name is `exiftool(-k).exe`. Delete the `(-k)` in the file name. 
 - You need to add data about the camera make, camera model, and focal length to the image files themselves -
 - **Move** the file `exiftool.exe` to the folder where your images are.
 - **Mac users** Unzip if you need to, double click on the dmg file, follow the prompts. You're good to go.

2. Navigate to where your images are store. Windows users, search your machine for `command prompt`. Mac users, search your machine for `terminal`. Run that program. This opens up a window where you can type commands into your computer. You use the `cd` command to 'change directories', followed by the exact location (path) of your images. On a PC it'll probably look something like `cd c:\users\yourname\documents\myimages`.  When you're in the location, `dir` will show you everything in that director. Mac users, the command `ls` will list the directory contents. Make sure you're in the right location, (and windows users, that `exiftool.exe` is in that directory).

3. The following commands will add the required metadata to your images. Note that each command is saying, in effect, exiftool, change the following metadata field to this new setting for the following image. the `*.jpeg` means, every single jpeg in this folder. **NB** if your files end with .jpg, you'd use `.jpg`, right?
 - ```exiftool -FocalLength="3.97" *.jpeg``` . <- sets the focal length of your image at 3.97 mm. You should search for your cellphone make online to see if you can find the actual measurement. If you can't find it, 3.97 is probably close enough.
 - ```exiftool -Make="CameraMake" *.jpeg``` <- you can use whatever value you want instead of `CameraMake`. E.g., `myphone` works.
 - ```exiftool -Model="CameraModel" *.jpeg``` <- you can use whatever value you want.  
 - If all goes according to plan, the computer will report the number of images modified. Exiftool also makes a copy of your images with the new file extension, `.jpeg_original` so that if something goes wrong, you can delete the new files and restore the old ones by changing their file names (eg, remove `_original` from the name).

4. Regard3d looks for that metadata in order to do the calculations that generate the point cloud from which the model is created. It needs the focal length, and it needs the size of the image sensor to work. It reads the metadata on make and model and compares it against a database of cameras to get the size of the image sensor plate. Oddly enough, this information is **not** encoded in the image metadata, which is why we need the database. This database is just a text file that uses commas to delimit the fields of information. The pattern looks like this: ```make;model;width-in-mm```. EG: `Canon;Canon-sure-shot;6`. So, we find that file, and we add that information at the end of it.
 - **windows users** This information will be at this location: ```C:\Users\[User name]\AppData\Local\Regard3D``` eg, on my PC: ```C:\Users\ShawnGraham\AppData\Local\Regard3D```, and is in the file "sensor_database.csv".
 - ***mac users** Open your finder, and hit shift+command+g and go to `/Applications/Regard3D.app/Contents/Resources`
 - Do not open `sensor_database.csv` with Excel; Excel will add hidden characters and screw everything up. Instead, you need a proper text editor to work with the file (notepad or wordpad are not useful here). One good option is [Sublime Text](https://www.sublimetext.com/). Download, install, and use it to open `sensor_database.csv`
 - Add whatever you put in for camera make and camera model (back in step 3) *exactly* - uppercase/lowercase matters. You can search to find the size of the image sensor for your cell phone camera. Use that info if you can find it; otherwise 6 mm is probably pretty close.
- ```ShawnsPhone;LG3;6```
- Save.

Now you can open Regard3d, 'add a picture set', select these images, and Regard3d will have all of the necessary metadata with which to work.


Build the model

Open Regard3d and start a new project. Add a photoset by selecting your frames directory. Note that when you
used the exiftool, the original images were copied within the folder with a new name. Don't select those original
images. As the images load up, you will see whether or not your metadata is being correctly read. If you get NaN
under make, model, focal length, or sensor width, revisit step three again carefully. Click ok to use the images.
Click on compute matches. Slide the keypoint density sliders (two sliders) all the way to 'ultra'. You can try with
just the default values at first, which is faster, but using 'ultra' means we get as many data points as possible,
which can be necessary given our source images.
This might take some time. When it is finished, proceed through the next steps as Regard3d presents them to
you (the options in the bottom left panel of the program are context-specific. If you want to revisit a previous
step and try different settings, select the results from that step in the inspector panel top left to redo).
The final procedure in model generation is to compute the surfaces. When you click on the 'surface' button
(having just completed the 'densification' step), make sure to tick off the 'texture' radio button. When this step is
complete, you can hit the 'export' button. The model will be in your project folder - .obj, .stl., and .png. To share
the model on something like Sketchfab.com zip these three files into a single zip folder. On sketchfab, you upload
the zip folder.



Step Five Clean Up
Double click on the .obj file in your project folder. Meshlab will open and display your model. The exact tools you
might wish to use to enhance or clean up your model depends very much on how your model turned out. At the
very least, you'll use the 'vertice select' tool (which allows you to draw a box over the offending part) and the
'vertice delete' tool. Search the web for help and examples for the effective use of Meshlab.


link to humcommons piece for the archival build